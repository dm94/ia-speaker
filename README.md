# IA Speaker

Una aplicaciÃ³n web para conversaciones por voz con inteligencia artificial que funciona completamente de manera local. Utiliza LM Studio para generaciÃ³n de texto y el modelo sesame/csm-1b para sÃ­ntesis de voz.

## ğŸš€ CaracterÃ­sticas

- **ConversaciÃ³n por voz bidireccional** con IA
- **Funcionamiento completamente local** - sin dependencias de servicios en la nube
- **IntegraciÃ³n con LM Studio** para generaciÃ³n de texto
- **SÃ­ntesis de voz avanzada** usando sesame/csm-1b
- **Interfaz moderna** construida con React y TypeScript
- **Historial de conversaciones** con bÃºsqueda
- **ConfiguraciÃ³n flexible** de parÃ¡metros de IA y audio

## ğŸ› ï¸ TecnologÃ­as

- **Frontend**: React 18 + TypeScript + Tailwind CSS
- **Backend**: Python + FastAPI (para sÃ­ntesis de voz)
- **IA**: LM Studio (generaciÃ³n de texto) + sesame/csm-1b (sÃ­ntesis de voz)
- **Audio**: Web Audio API + Web Speech API

## ğŸ“‹ Requisitos Previos

### Software Necesario
1. **Node.js** (v18 o superior)
2. **Python** (v3.8 o superior)
3. **LM Studio** - [Descargar aquÃ­](https://lmstudio.ai/)
4. **CUDA** (opcional, para aceleraciÃ³n GPU)

### Modelos Requeridos
1. **Modelo de lenguaje** en LM Studio (ej: Llama, Mistral, etc.)
2. **sesame/csm-1b** para sÃ­ntesis de voz

## ğŸš€ InstalaciÃ³n

### 1. Clonar el Repositorio
```bash
git clone <repository-url>
cd ia-speaker
```

### 2. Instalar Dependencias del Frontend
```bash
pnpm install
# o
npm install
```

### 3. Configurar Backend Python (SÃ­ntesis de Voz)

Crea un entorno virtual de Python:
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

Instala las dependencias de Python:
```bash
pip install fastapi uvicorn torch transformers datasets
```

### 4. Configurar LM Studio

1. Descarga e instala [LM Studio](https://lmstudio.ai/)
2. Descarga un modelo de lenguaje (recomendado: Llama 3.1 8B o similar)
3. Inicia el servidor local en LM Studio:
   - Ve a la pestaÃ±a "Local Server"
   - Selecciona tu modelo
   - Inicia el servidor en `http://localhost:1234`

## ğŸ¯ Uso

### 1. Iniciar el Backend Python

Crea un archivo `backend/main.py`:
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import torch
from transformers import CsmForConditionalGeneration, AutoProcessor

app = FastAPI()

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Cargar modelo sesame/csm-1b
model_id = "sesame/csm-1b"
device = "cuda" if torch.cuda.is_available() else "cpu"
processor = AutoProcessor.from_pretrained(model_id)
model = CsmForConditionalGeneration.from_pretrained(model_id, device_map=device)

@app.post("/synthesize")
async def synthesize_speech(request: dict):
    text = request.get("text", "")
    
    # Preparar inputs
    inputs = processor(f"[0]{text}", add_special_tokens=True).to(device)
    
    # Generar audio
    audio = model.generate(**inputs, output_audio=True)
    
    # Guardar y retornar audio
    audio_path = "output.wav"
    processor.save_audio(audio, audio_path)
    
    return {"audio_url": f"/audio/{audio_path}"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

Inicia el backend:
```bash
cd backend
python main.py
```

### 2. Iniciar el Frontend

En otra terminal:
```bash
pnpm dev
# o
npm run dev
```

### 3. Configurar la AplicaciÃ³n

1. Abre `http://localhost:5173` en tu navegador
2. Ve a la pÃ¡gina de **ConfiguraciÃ³n**
3. Configura:
   - **URL de LM Studio**: `http://localhost:1234`
   - **Modelo**: Nombre del modelo cargado en LM Studio
   - **ParÃ¡metros de audio**: Ajusta segÃºn tus preferencias

### 4. Â¡Comenzar a Conversar!

1. Ve a la **PÃ¡gina Principal**
2. Presiona el botÃ³n del micrÃ³fono
3. Habla tu pregunta
4. Escucha la respuesta generada

## ğŸ“ Estructura del Proyecto

```
ia-speaker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # Componentes reutilizables
â”‚   â”œâ”€â”€ pages/              # PÃ¡ginas principales
â”‚   â”‚   â”œâ”€â”€ Home.tsx        # PÃ¡gina de conversaciÃ³n
â”‚   â”‚   â”œâ”€â”€ Configuration.tsx # ConfiguraciÃ³n
â”‚   â”‚   â””â”€â”€ History.tsx     # Historial
â”‚   â”œâ”€â”€ types/              # Declaraciones de tipos
â”‚   â””â”€â”€ lib/                # Utilidades
â”œâ”€â”€ backend/                # Backend Python (crear)
â”‚   â””â”€â”€ main.py            # Servidor FastAPI
â”œâ”€â”€ public/                 # Archivos estÃ¡ticos
â””â”€â”€ README.md              # Este archivo
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno

Crea un archivo `.env` en la raÃ­z del proyecto:
```env
VITE_LM_STUDIO_URL=http://localhost:1234
VITE_BACKEND_URL=http://localhost:8000
```

### PersonalizaciÃ³n del Modelo de Voz

Puedes ajustar los parÃ¡metros del modelo sesame/csm-1b en el backend:
- **Velocidad de habla**
- **Tono de voz**
- **Calidad de audio**

## ğŸ”§ SoluciÃ³n de Problemas

### Error de MicrÃ³fono
- Verifica que el navegador tenga permisos de micrÃ³fono
- Usa HTTPS en producciÃ³n para acceso al micrÃ³fono

### Error de ConexiÃ³n con LM Studio
- AsegÃºrate de que LM Studio estÃ© ejecutÃ¡ndose
- Verifica que el servidor local estÃ© activo en el puerto 1234
- Comprueba la configuraciÃ³n de CORS en LM Studio

### Error de SÃ­ntesis de Voz
- Verifica que el backend Python estÃ© ejecutÃ¡ndose
- AsegÃºrate de tener suficiente memoria RAM/VRAM para el modelo
- Comprueba que las dependencias de Python estÃ©n instaladas

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- [Sesame](https://huggingface.co/sesame) por el modelo CSM-1B
- [LM Studio](https://lmstudio.ai/) por la plataforma de modelos locales
- [Hugging Face](https://huggingface.co/) por las herramientas de transformers
